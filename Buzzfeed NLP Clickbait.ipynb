{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickbait or Not?\n",
    "\n",
    "The main goal of this project is to classify, using Natural Language Processing, the titles that are considered clickbait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Reading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_bait = pd.read_csv('clickbait_titles.csv')\n",
    "serious_titles = pd.read_csv('non_clickbait_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Adding the labels\n",
    "---------------------------\n",
    "#####       1 for clickbait titles\n",
    "#####       0 for not-clickbait titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_bait['label'] = 1\n",
    "serious_titles['label'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.4 Removing useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_bait = click_bait[['title', 'label']]\n",
    "serious_titles = serious_titles[['title', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(click_bait.head())\n",
    "display(serious_titles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Items {Clickbait}: ', click_bait.shape[0])\n",
    "print('Items {Not-Clickbait}: ', serious_titles.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Concatenating both datasets in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.concat([click_bait, serious_titles], axis = 0, ignore_index = True)\n",
    "titles.to_csv('clickbait_or_not.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Defining the feature and the label variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titles['title']\n",
    "y = titles['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tamanho do X_train: ', X_train.shape, '\\t', 'tamanho do y_train: ', y_train.shape)\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('tamanho do X_test: ', X_test.shape, '\\t', 'tamanho do y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Assigning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_clf = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "complement_clf = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', ComplementNB())])\n",
    "\n",
    "svm_clf = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', svm.SVC(kernel = 'linear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_clf.fit(X_train, y_train)\n",
    "complement_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Predicting the test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mult = multinomial_clf.predict(X_test)\n",
    "pred_complement = complement_clf.predict(X_test)\n",
    "pred_svm = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Checking the precision of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MultinomialNB Score:', str(round(f1_score(pred_mult, y_test), 4) * 100)+'%')\n",
    "print('ComplementNB Score:', str(round(f1_score(pred_complement, y_test), 4) * 100)+'%')\n",
    "print('SVM Score:', str(round(f1_score(pred_svm, y_test), 4) * 100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2  Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, pred_mult), annot = True, fmt = '.2f')\n",
    "plt.title('MultinomialNB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Precision/Recall/F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_mult, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score:', accuracy_score(y_test, pred_mult), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, treshold = roc_curve(y_test, pred_mult)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Validating with recent titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ['Escolha um ídolo do k-pop e nós indicaremos seu produto de beleza ideal',\n",
    "        'Senador gay coloca Augusto Aras contra a parede: \"Tenho subfamília? Sou doente?\"',\n",
    "        'Suas opiniões sobre estas tendências atuais da moda vão nos dizer se você faz parte da geração millennial ou da geração Z',\n",
    "        '“Outras Ágathas virão”, diz oposição sobre pacote de Moro',\n",
    "        'Planeje sua invasão à Área 51 e descubra qual E.T. você vai encontrar por lá',\n",
    "        '10 livros com cartas de amor de gente meio passional',\n",
    "        '“Recomendo que procure ajuda psiquiátrica”, diz Gilmar Mendes sobre Janot',\n",
    "        'O pior é ter que concordar com o Gilmar, dizem aliados que romperam com Janot',\n",
    "        'Cheesecake nunca é demais!',\n",
    "        'O Facebook confirmou que políticos podem publicar o que quiserem, seja falso ou não']\n",
    "\n",
    "val_y = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = multinomial_clf.predict(val)\n",
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation Score: ', str(f1_score(val_pred, val_y) * 100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Model persistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = joblib.dump(multinomial_clf, 'Naive Bayes Buzzfeed Classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('Naive Bayes Buzzfeed Classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Predicting with the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
